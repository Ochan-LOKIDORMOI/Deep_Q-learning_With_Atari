# **Deep Q-learning With Atari- Training and Playing Breakout**

This project trains a **Deep Q-Network (DQN) agent** using Stable Baselines3 and Gymnasium to play **Breakout**â€”a classic Atari game where the goal is to break bricks using a bouncing ball. The agent learns to maximize its score by optimizing its actions through reinforcement learning.

## Environment Selection

**Game:** Breakout

**Environment:** ALE/Breakout-v5 (from Gymnasiumâ€™s Atari collection)

**Objective:** Train a DQN agent to break bricks efficiently while keeping the ball in play

## Understanding Rward strategy

**Discrete Reward System**

Breakout uses a discrete reward strategy because the game has a clear win/lose condition:

The agent earns rewards for breaking bricks.

The episode terminates when the ball falls below the paddle.

## Project Structure



## Hyperparameter Tuning Results




## Group Contributions

This project was a group effort, with each team member contributing to different aspects of training and evaluation.

Team Members:

1. Ochan LOKIDORMOI

2. Elvis Bakunzi

3. Kathrine Ganda

ðŸ“Œ Work Distribution

Each member trained and tested a model using different hyperparameters to compare performance.

Results were discussed, and the best-performing model was selected for the final evaluation.

Team members collaborated on the README documentation and presentation preparation.

